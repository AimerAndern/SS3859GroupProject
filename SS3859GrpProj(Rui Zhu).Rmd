---
title: "SS3859 Group Project"
author: "Rui Zhu"
output:
  word_document: default
  html_notebook: default
  pdf_document: default
  html_document:
    df_print: paged
---


\newpage
# Calculate p-value for each predictor
```{r}

df <- read.csv(file = 'PRSA_data_2010.1.1-2014.12.31.csv')
df=na.omit(df)
set.seed(3859)
index <- sample(1:nrow(df), 2000)
df=df[index, ]
nrow(df)
head(df)
model1=lm(pm2.5 ~ DEWP+TEMP+PRES+cbwd+Iws+Is+Ir, data=df)
summary(model1)

```

# Some hypothese that which predictors are not significant 
 * By observing the summary table of the full model, we make the null hypothesis that the Is is not significantly important to explain this model.
```{r}
#reduced model without Is
model2=lm(pm2.5 ~ DEWP+TEMP+PRES+Iws+cbwd+Ir, data=df)
summary(model2)
anova(model1,model2)
```

 * The large f statistics value in anova indicates there is no significant difference between the two models. Therefore, we fail to reject the null hypothesis that Is is significantly important to explain the model.
 

 
 
 
# Test for interactions(2 way interaction)
```{r}
model4=lm(pm2.5 ~ DEWP+TEMP+PRES+cbwd+Iws+Ir+Is+I(DEWP*TEMP)+I(DEWP*PRES)+I(DEWP*Iws)+I(DEWP*Ir)+I(TEMP*PRES)+I(TEMP*Iws)+I(TEMP*Ir)+I(PRES*Iws)+I(PRES*Ir)+I(Iws*Ir)+I(Is*TEMP)+I(Is*DEWP)+I(Is*PRES)+I(Is*Iws)+I(Is*Ir), data=df)


summary(model4)
```
 * By observing the p-value of each predictior, we make the null hypothesis that DEWP * TEMP, DEWP * Ir, TEMP * Ir and PRES * Ir, Is * TEMP, Is * DEWP and Is * PRES are not significantly important to explain this model. 
```{r}
#reduced model without DEWP * TEMP, DEWP * Ir, TEMP * Ir and PRES * Ir, Is * TEMP, Is * DEWP and Is * PRES
model5=lm(pm2.5 ~ DEWP+TEMP+PRES+cbwd+Iws+Ir+Is+I(DEWP*PRES)+I(DEWP*Iws)+I(TEMP*PRES)+I(TEMP*Iws)+I(PRES*Iws)+I(Iws*Ir)+I(Is*Iws)+I(Is*Ir), data=df)
summary(model5)
anova(model4,model5)
```
 * The large p-value in anova indicates there is no significant difference between the two models.
 
 
# Variable selection (which variables to keep, based on previous results and AIC, BIC or PRESS test)
```{r}
nullfit <- lm(pm2.5~1,data=df)
stepAppro_aic = step(nullfit,
                     scope = pm2.5 ~ DEWP+TEMP+PRES+cbwd+Iws+Ir+Is+I(DEWP*TEMP)+I(DEWP*PRES)+I(DEWP*Iws)+I(DEWP*Ir)+I(TEMP*PRES)+I(TEMP*Iws)+I(TEMP*Ir)+I(PRES*Iws)+I(PRES*Ir)+I(Iws*Ir)+I(Is*TEMP)+I(Is*DEWP)+I(Is*PRES)+I(Is*Iws)+I(Is*Ir),
                     direction = "forward",
                     trace = 0)

stepAppro_bic <- step(model4,
                      direction = "backward",
                      k=log(nrow(df)),
                      trace=FALSE)
stepAppro_aic
stepAppro_bic
anova(stepAppro_aic,stepAppro_bic)
library(asbio)
#model selected by AIC
press(lm(formula = pm2.5 ~ Iws + I(TEMP * PRES) + I(DEWP * PRES) + 
    cbwd + DEWP + I(PRES * Ir) + PRES + I(DEWP * Iws) + I(TEMP * 
    Iws) + I(PRES * Iws) + I(Iws * Ir) + I(Is * TEMP) + I(Is * 
    Iws) + I(Is * PRES) + TEMP, data = df)
)
#model selected by BIC
press(lm(formula = pm2.5 ~ DEWP + PRES + cbwd + Iws + I(DEWP * PRES) + 
    I(DEWP * Iws) + I(TEMP * PRES) + I(TEMP * Iws) + I(PRES * 
    Ir) + I(Is * PRES) + I(Is * Iws), data = df))
```
 * The PRESS statistic indicates that model selected by AIC is more preferred in this case. However, PRESS might not be approprite although the dataset is reduced already.



# Model diagnostics on one well-fit model
```{r}
library(lmtest)
#we will be using the model selected by AIC in later learning
model=lm(formula = pm2.5 ~ Iws + I(TEMP * PRES) + I(DEWP * PRES) + 
    cbwd + DEWP + I(PRES * Ir) + PRES + I(DEWP * Iws) + I(TEMP * 
    Iws) + I(PRES * Iws) + I(Iws * Ir) + I(Is * TEMP) + I(Is * 
    Iws) + I(Is * PRES) + TEMP, data = df)
plot(fitted(model), resid(model),
     col = "blue", pch = 10,
     xlab = "fitted value",
     ylab = "residual",
     cex=1,
     main = "residual plot")
qqnorm(resid(model), col = "grey",pch=20,cex=2)
qqline(resid(model))
loggedModel=lm(formula = log(pm2.5) ~ Iws + I(TEMP * PRES) + I(DEWP * PRES) + 
    cbwd + DEWP + I(PRES * Ir) + PRES + I(DEWP * Iws) + I(TEMP * 
    Iws) + I(PRES * Iws) + I(Iws * Ir) + TEMP, data = df)
plot(fitted(loggedModel), resid(loggedModel),
     col = "blue", pch = 10,
     xlab = "fitted value",
     ylab = "residual",
     cex=1,
     main = "residual plot")
bptest(model)
shapiro.test(resid(model))

timeset=c()
residset=c()
i=1
while (i<nrow(df)){
  timeset=append(timeset, as.Date(paste(df[i,"month"],df[i,"day"],df[i,"year"],sep="/"), "%m/%d/%Y"))
  residset=append(residset, df[i, "pm2.5"]-predict(model, df[i,]))
  i=i+1
}
plot(timeset, residset,
     col = "blue", pch = 10,
     xlab = "time",
     ylab = "residual",
     cex=1,
     main = "residual plot")
length(timeset)

```
  * Assumptions:
  
    * Linearity: The residuals distribute systematically and do not exhibit a mean of 
    zero. The linearity assumption is violated.
  
    * Equal Variance: The small p-value of the BP test indicates that the  
    variance assumption is violated.
    
    * Normality Assumption: The small p-value of SW test indicates that the normality
    assumption is violated. However, the logged model might hold the normality assumption.
    
    * Independence Assumption: The residual plot against time, the value of random errors 
    are independent. The normality assumption holds.





































